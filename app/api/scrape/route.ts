import { NextRequest, NextResponse } from 'next/server';
import { ScraperService } from '@/lib/scraper';
import { ScrapeResponse, ErrorType } from '@/types';
import { RedisCache } from '@/lib/redis';

export async function GET(request: NextRequest) {
  try {
    // æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶åˆ·æ–°å’Œåˆ†é¡µå‚æ•°
    const { searchParams } = new URL(request.url);
    const forceRefresh = searchParams.get('refresh') === 'true';
    const page = parseInt(searchParams.get('page') || '1');
    const pageSize = parseInt(searchParams.get('pageSize') || '20');

    console.log(`ğŸ”„ API è¯·æ±‚ - å¼ºåˆ¶åˆ·æ–°: ${forceRefresh}, é¡µç : ${page}, æ¯é¡µ: ${pageSize}`);

    let paginatedItems: any[] = [];
    let total = 0;
    let lastUpdate = null;
    let shouldUpdate = false;

    // æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶åˆ·æ–°æˆ–è‡ªåŠ¨æ›´æ–°
    if (forceRefresh) {
      console.log('ğŸ”„ å¼ºåˆ¶åˆ·æ–°ï¼šä»APIè·å–æ•°æ®');
      const scraper = new ScraperService();
      const allItems = await scraper.scrapeAndProcess(true);

      // å­˜å‚¨åˆ°Redis
      await RedisCache.storeData(allItems, true);

      // åˆ†é¡µå¤„ç†
      const startIndex = (page - 1) * pageSize;
      const endIndex = startIndex + pageSize;
      paginatedItems = allItems.slice(startIndex, endIndex);
      total = allItems.length;
      lastUpdate = new Date().toISOString();
    } else {
      // æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ›´æ–°
      shouldUpdate = await RedisCache.shouldAutoUpdate();

      if (shouldUpdate) {
        console.log('â° å®šæ—¶æ›´æ–°ï¼šä»APIè·å–æ•°æ®');
        const scraper = new ScraperService();
        const allItems = await scraper.scrapeAndProcess(false);

        // å­˜å‚¨åˆ°Redis
        await RedisCache.storeData(allItems, false);

        // åˆ†é¡µå¤„ç†
        const startIndex = (page - 1) * pageSize;
        const endIndex = startIndex + pageSize;
        paginatedItems = allItems.slice(startIndex, endIndex);
        total = allItems.length;
        lastUpdate = new Date().toISOString();
      } else {
        // æ™®é€šåˆ·æ–°ï¼šä»Redisè¯»å–åˆ†é¡µæ•°æ®
        console.log('ğŸ“– æ™®é€šåˆ·æ–°ï¼šä»Redisè¯»å–æ•°æ®');
        const redisData = await RedisCache.getPagedData(page, pageSize);
        paginatedItems = redisData.items;
        total = redisData.total;
        lastUpdate = redisData.lastUpdate;
      }
    }

    const response: ScrapeResponse = {
      success: true,
      data: paginatedItems,
      timestamp: new Date().toISOString(),
      metadata: {
        forceRefresh,
        itemCount: paginatedItems.length,
        total,
        page,
        pageSize,
        hasMore: paginatedItems.length === pageSize,
        lastUpdate,
        shouldUpdate,
      },
    };

    return NextResponse.json(response, {
      headers: {
        'Cache-Control': forceRefresh ? 'no-cache, no-store, must-revalidate' : 's-maxage=60, stale-while-revalidate',
      },
    });
  } catch (error: any) {
    console.error('Scrape error:', error);

    let errorMessage = 'çˆ¬å–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•';

    if (error.message === ErrorType.TIMEOUT_ERROR) {
      errorMessage = 'è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥';
    } else if (error.message === ErrorType.NETWORK_ERROR) {
      errorMessage = 'ç½‘ç»œé”™è¯¯ï¼Œæ— æ³•è¿æ¥åˆ°ç›®æ ‡ç½‘ç«™';
    } else if (error.message === ErrorType.PARSE_ERROR) {
      errorMessage = 'å†…å®¹è§£æå¤±è´¥';
    }

    const response: ScrapeResponse = {
      success: false,
      error: errorMessage,
      timestamp: new Date().toISOString(),
    };

    return NextResponse.json(response, { status: 500 });
  }
}
